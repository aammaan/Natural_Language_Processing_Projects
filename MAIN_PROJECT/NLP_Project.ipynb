{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8204601,"sourceType":"datasetVersion","datasetId":4861104},{"sourceId":37638,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":31635}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BertTokenizer, BertForTokenClassification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:24:54.474930Z","iopub.execute_input":"2024-04-26T10:24:54.475823Z","iopub.status.idle":"2024-04-26T10:25:03.153851Z","shell.execute_reply.started":"2024-04-26T10:24:54.475787Z","shell.execute_reply":"2024-04-26T10:25:03.153079Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('/kaggle/input/train-json/Subtask_1_train.json', 'r') as file:\n    data = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:06.004525Z","iopub.execute_input":"2024-04-26T10:25:06.005410Z","iopub.status.idle":"2024-04-26T10:25:06.315384Z","shell.execute_reply.started":"2024-04-26T10:25:06.005377Z","shell.execute_reply":"2024-04-26T10:25:06.314511Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"conversation_list = []\n\nfor i in data:\n    \n    temp = i['conversation']\n    text_list = []\n    for j in temp:\n        text_list.append(j['text'])\n    \n    emotion_cause = i['emotion-cause_pairs']\n    ec_dict = {}\n    for j in emotion_cause:\n        if j[0] not in ec_dict:\n            ec_dict[j[0]] = [j[1]]\n        else:\n            ec_dict[j[0]].append(j[1])\n            \n    conversation_list.append({'text':text_list,'emotion_cause': ec_dict})\n    \nprint(len(conversation_list))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:08.024583Z","iopub.execute_input":"2024-04-26T10:25:08.024945Z","iopub.status.idle":"2024-04-26T10:25:08.044397Z","shell.execute_reply.started":"2024-04-26T10:25:08.024917Z","shell.execute_reply":"2024-04-26T10:25:08.043298Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"1374\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in conversation_list:\n    print(i)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:09.979819Z","iopub.execute_input":"2024-04-26T10:25:09.980164Z","iopub.status.idle":"2024-04-26T10:25:09.985386Z","shell.execute_reply.started":"2024-04-26T10:25:09.980137Z","shell.execute_reply":"2024-04-26T10:25:09.984461Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'text': ['Alright , so I am back in high school , I am standing in the middle of the cafeteria , and I realize I am totally naked .', 'Oh , yeah . Had that dream .', 'Then I look down , and I realize there is a phone ... there .', 'Instead of ... ?', 'That is right .', 'Never had that dream .', 'No .', 'All of a sudden , the phone starts to ring .'], 'emotion_cause': {'3_surprise': ['1_I realize I am totally naked .', '3_Then I look down , and I realize there is a phone ... there .'], '4_surprise': ['1_I realize I am totally naked .', '3_Then I look down , and I realize there is a phone ... there .', '4_Instead of ...'], '5_anger': ['1_I realize I am totally naked .', '3_Then I look down , and I realize there is a phone ... there .', '4_Instead of ...']}}\n","output_type":"stream"}]},{"cell_type":"code","source":"def finder(list1, list2):\n    i = 0\n    j = 0\n    while i<len(list1):\n        if(list1[i]==list2[j]):\n            j+=1\n        else:\n            j=0\n        if(j == len(list2)):\n            return i-j+1, i+1\n        i+=1\n    return -1, -1\n\n# print(finder([1,24,223,4,23,5,342,12,42],[223,4,23,5]))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:12.075726Z","iopub.execute_input":"2024-04-26T10:25:12.076116Z","iopub.status.idle":"2024-04-26T10:25:12.082555Z","shell.execute_reply.started":"2024-04-26T10:25:12.076084Z","shell.execute_reply":"2024-04-26T10:25:12.081457Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"emotion_list = ['anger','joy','fear','disgust','surprise','sadness','overall']\ndata_dict = {}\nfor i in emotion_list:\n    data_dict[i] = []\n    \nfor i in conversation_list:\n    \n    text_list = i['text']\n    emotion_list = i['emotion_cause']\n    \n    for j in emotion_list:\n        \n        data_item = {}\n        temp = j.split(\"_\")\n        idx=int(j[0])\n        emotion= temp[1]\n        emotion_cause_list = emotion_list[j]\n        \n        text= []\n        label = []\n        \n        for k in range(idx):\n            temp_text = text_list[k].split()\n            temp_label = [0]*len(temp_text)\n            \n            text.extend(temp_text)\n            label.extend(temp_label)\n            \n        for k in emotion_cause_list:\n            \n            temp = k.split(\"_\")[1].split()\n            s_idx, l_idx = finder(text, temp)\n\n            for x in range(s_idx,l_idx):\n                label[x] = 1\n\n        data_item['text'] = text\n        data_item['label'] = label\n        data_dict[emotion].append(data_item)\n        data_item['text'] = [emotion,':'] + text\n        data_item['label'] = [1,0] + label\n        data_dict['overall'].append(data_item)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:15.462016Z","iopub.execute_input":"2024-04-26T10:25:15.462697Z","iopub.status.idle":"2024-04-26T10:25:15.756021Z","shell.execute_reply.started":"2024-04-26T10:25:15.462661Z","shell.execute_reply":"2024-04-26T10:25:15.754962Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for i in data_dict['surprise']:\n    print(i)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:20.224570Z","iopub.execute_input":"2024-04-26T10:25:20.224937Z","iopub.status.idle":"2024-04-26T10:25:20.230376Z","shell.execute_reply.started":"2024-04-26T10:25:20.224907Z","shell.execute_reply":"2024-04-26T10:25:20.229346Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'text': ['surprise', ':', 'Alright', ',', 'so', 'I', 'am', 'back', 'in', 'high', 'school', ',', 'I', 'am', 'standing', 'in', 'the', 'middle', 'of', 'the', 'cafeteria', ',', 'and', 'I', 'realize', 'I', 'am', 'totally', 'naked', '.', 'Oh', ',', 'yeah', '.', 'Had', 'that', 'dream', '.', 'Then', 'I', 'look', 'down', ',', 'and', 'I', 'realize', 'there', 'is', 'a', 'phone', '...', 'there', '.'], 'label': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}]},{"cell_type":"code","source":"emotion_list = ['anger','joy','fear','disgust','surprise','sadness','overall']\n\nfor i in emotion_list:\n    print(i)\n    print(len(data_dict[i]))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:25.889840Z","iopub.execute_input":"2024-04-26T10:25:25.890734Z","iopub.status.idle":"2024-04-26T10:25:25.896454Z","shell.execute_reply.started":"2024-04-26T10:25:25.890701Z","shell.execute_reply":"2024-04-26T10:25:25.895327Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"anger\n1373\njoy\n2093\nfear\n255\ndisgust\n375\nsurprise\n1624\nsadness\n1041\noverall\n6761\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        text = self.data[idx]['text']\n        label = self.data[idx]['label']\n        label = label + [0]*(512-len(label))\n        text_str = \"\"   \n        for k in text:\n            text_str+=k\n            text_str+=\" \"\n        inputs = self.tokenizer(text_str, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n        inputs['input_ids'] = inputs['input_ids'].reshape([512])\n        inputs['token_type_ids'] = inputs['token_type_ids'].reshape([512])\n        inputs['attention_mask'] = inputs['attention_mask'].reshape([512])\n        \n        return [inputs, torch.tensor(label, dtype=torch.long)]","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:27.881171Z","iopub.execute_input":"2024-04-26T10:25:27.881570Z","iopub.status.idle":"2024-04-26T10:25:27.889970Z","shell.execute_reply.started":"2024-04-26T10:25:27.881543Z","shell.execute_reply":"2024-04-26T10:25:27.888921Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:30.233017Z","iopub.execute_input":"2024-04-26T10:25:30.233934Z","iopub.status.idle":"2024-04-26T10:25:30.975211Z","shell.execute_reply.started":"2024-04-26T10:25:30.233892Z","shell.execute_reply":"2024-04-26T10:25:30.974041Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93ff380a2d464fe6825a616763fc67d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eaecf9a82ba4363bd5eac23fe3ab688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2d1ed46ea85468f9cacb27ae76634d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83439f20c6554832a8fe25ee3e7afe66"}},"metadata":{}}]},{"cell_type":"code","source":"train_loader_dict = {}\nval_loader_dict = {}\n\nfor i in emotion_list:\n    train_data, val_data = train_test_split(data_dict[i], test_size=0.2, random_state=42)\n    train_loader_dict[i] = DataLoader(CustomDataset(train_data, tokenizer), batch_size=16, shuffle=True)\n    val_loader_dict[i]= DataLoader(CustomDataset(val_data, tokenizer), batch_size=2, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:39.881462Z","iopub.execute_input":"2024-04-26T10:25:39.882242Z","iopub.status.idle":"2024-04-26T10:25:39.899409Z","shell.execute_reply.started":"2024-04-26T10:25:39.882214Z","shell.execute_reply":"2024-04-26T10:25:39.898490Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"learning_rate = 2e-5\nemotion_list = ['anger','joy','fear','disgust','surprise','sadness','overall']\nmodel_dict = {}\noptimizer_dict = {}\nfor i in emotion_list:\n    temp_model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=2).to(device)\n    temp_optimizer = optimizer = torch.optim.AdamW(temp_model.parameters(), lr=learning_rate)\n    model_dict[i] = temp_model\n    optimizer_dict[i] = temp_optimizer","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:25:43.199978Z","iopub.execute_input":"2024-04-26T10:25:43.200317Z","iopub.status.idle":"2024-04-26T10:25:48.939353Z","shell.execute_reply.started":"2024-04-26T10:25:43.200292Z","shell.execute_reply":"2024-04-26T10:25:48.938488Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c98a3588834d4bbfeba43201036996"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nmodel = model_dict['sadness']\noptimizer = optimizer_dict['sadness']\ntrain_loader = train_loader_dict['sadness']\nval_loader = val_loader_dict['sadness']\n                             \nmax_f1 = 0\n\nepochs = 15\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    \n    for batch in train_loader:\n        inputs = batch[0].to(device)\n        labels = batch[1].to(device)\n        optimizer.zero_grad()\n        outputs = model(**inputs, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n    \n    avg_train_loss = total_loss / len(train_loader)\n    print(f'Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_train_loss:.4f}')\n\n    # Validation loop\n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    collated_total = []\n    predicted_total = []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = batch[0].to(device)\n            labels = batch[1].to(device)\n            outputs = model(**inputs, labels=labels)\n            loss, scores = outputs[:2]\n            loss = outputs.loss\n            val_loss += loss.item()\n            predicted = outputs.logits.argmax(dim=-1)\n            collated_total.extend(labels.flatten().tolist())\n            predicted_total.extend(predicted.flatten().tolist())\n\n    avg_val_loss = val_loss / len(val_loader)\n    f1 = f1_score(collated_total, predicted_total)\n    if(f1>max_f1):\n        max_f1 = f1\n        torch.save(model.state_dict(), 'sadness_model.pth')\n    print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}, F1: {f1}')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T08:22:27.770030Z","iopub.execute_input":"2024-04-25T08:22:27.770306Z","iopub.status.idle":"2024-04-25T08:43:01.191001Z","shell.execute_reply.started":"2024-04-25T08:22:27.770282Z","shell.execute_reply":"2024-04-25T08:43:01.190043Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/15, Average Training Loss: 0.0801\nEpoch 1/15, Validation Loss: 0.0358, F1: 0.26973684210526316\nEpoch 2/15, Average Training Loss: 0.0370\nEpoch 2/15, Validation Loss: 0.0311, F1: 0.5231158961367954\nEpoch 3/15, Average Training Loss: 0.0316\nEpoch 3/15, Validation Loss: 0.0292, F1: 0.46759085799925065\nEpoch 4/15, Average Training Loss: 0.0273\nEpoch 4/15, Validation Loss: 0.0362, F1: 0.5921296296296296\nEpoch 5/15, Average Training Loss: 0.0223\nEpoch 5/15, Validation Loss: 0.0311, F1: 0.605890603085554\nEpoch 6/15, Average Training Loss: 0.0184\nEpoch 6/15, Validation Loss: 0.0344, F1: 0.5985699693564862\nEpoch 7/15, Average Training Loss: 0.0141\nEpoch 7/15, Validation Loss: 0.0364, F1: 0.6246169560776303\nEpoch 8/15, Average Training Loss: 0.0118\nEpoch 8/15, Validation Loss: 0.0371, F1: 0.6158881285331748\nEpoch 9/15, Average Training Loss: 0.0097\nEpoch 9/15, Validation Loss: 0.0415, F1: 0.6241664443851694\nEpoch 10/15, Average Training Loss: 0.0089\nEpoch 10/15, Validation Loss: 0.0449, F1: 0.6168903803131991\nEpoch 11/15, Average Training Loss: 0.0082\nEpoch 11/15, Validation Loss: 0.0417, F1: 0.6512861309997348\nEpoch 12/15, Average Training Loss: 0.0059\nEpoch 12/15, Validation Loss: 0.0475, F1: 0.6450431598221292\nEpoch 13/15, Average Training Loss: 0.0049\nEpoch 13/15, Validation Loss: 0.0444, F1: 0.6443514644351465\nEpoch 14/15, Average Training Loss: 0.0042\nEpoch 14/15, Validation Loss: 0.0491, F1: 0.6550709124966552\nEpoch 15/15, Average Training Loss: 0.0036\nEpoch 15/15, Validation Loss: 0.0520, F1: 0.6391257995735609\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nmodel = model_dict['surprise']\noptimizer = optimizer_dict['surprise']\ntrain_loader = train_loader_dict['surprise']\nval_loader = val_loader_dict['surprise']\nstate_dict = torch.load('/kaggle/input/surprise_model/pytorch/surprise/1/surprise_model.pth')\nmodel.load_state_dict(state_dict)\n                             \nmax_f1 = 0\n\nmodel.eval()\nval_loss = 0\ncorrect = 0\ntotal = 0\ncollated_total = []\npredicted_total = []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        inputs = batch[0].to(device)\n        labels = batch[1].to(device)\n        outputs = model(**inputs, labels=labels)\n        loss, scores = outputs[:2]\n        loss = outputs.loss\n        val_loss += loss.item()\n        predicted = outputs.logits.argmax(dim=-1)\n        collated_total.extend(labels.flatten().tolist())\n        predicted_total.extend(predicted.flatten().tolist())\n\navg_val_loss = val_loss / len(val_loader)\nf1 = f1_score(collated_total, predicted_total)\nprint(f'Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}, F1: {f1}')","metadata":{"execution":{"iopub.status.busy":"2024-04-26T10:27:15.285989Z","iopub.execute_input":"2024-04-26T10:27:15.286802Z","iopub.status.idle":"2024-04-26T10:27:26.918424Z","shell.execute_reply.started":"2024-04-26T10:27:15.286761Z","shell.execute_reply":"2024-04-26T10:27:26.917038Z"},"trusted":true},"execution_count":13,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m val_loader_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurprise\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/surprise_model/pytorch/surprise/1/surprise_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m max_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForTokenClassification:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([30522, 768]) from checkpoint, the shape in current model is torch.Size([28996, 768])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for BertForTokenClassification:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([30522, 768]) from checkpoint, the shape in current model is torch.Size([28996, 768]).","output_type":"error"}]},{"cell_type":"code","source":"def text_tokenizer(text, label, tokenizer):\n    label = label + [0]*(512-len(label))\n    text_str = \"\"   \n    for k in text:\n        text_str+=k\n        text_str+=\" \"\n    inputs = tokenizer(text_str, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n    return [inputs, torch.tensor(label, dtype=torch.long)]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T08:43:02.476251Z","iopub.status.idle":"2024-04-25T08:43:02.476676Z","shell.execute_reply.started":"2024-04-25T08:43:02.476491Z","shell.execute_reply":"2024-04-25T08:43:02.476507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def idx_returner(list1):\n    ans = []\n    s_idx = -1\n    l_idx = -1\n    for i, item in enumerate(list1):\n        if item==1 and s_idx==-1:\n            s_idx = i\n        if item==1 and s_idx!=-1:\n            l_idx = i\n        if item==0 and l_idx!=-1:\n            ans.append([s_idx+2,l_idx+2])\n            s_idx=-1\n            l_idx=-1\n    if(s_idx!=-1 and l_idx!=-1):\n        ans.append([s_idx+2,l_idx+2])\n    print(ans)\n            ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T08:43:02.478187Z","iopub.status.idle":"2024-04-25T08:43:02.478665Z","shell.execute_reply.started":"2024-04-25T08:43:02.478424Z","shell.execute_reply":"2024-04-25T08:43:02.478444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in data_dict['overall'][52:]:\n    text_list = i['text']\n    true_label = i['label']\n    inputs, _ = text_tokenizer(text_list, true_label, tokenizer)\n    inputs = inputs.to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted = outputs.logits.argmax(dim=-1)\n    final_predicted = predicted.flatten().tolist()[:len(text_list)]\n    print(final_predicted)\n    print(true_label)\n    emotion = text_list[0]\n    idx_returner(final_predicted[2:])\n    break","metadata":{"execution":{"iopub.status.busy":"2024-04-25T08:43:02.480473Z","iopub.status.idle":"2024-04-25T08:43:02.480959Z","shell.execute_reply.started":"2024-04-25T08:43:02.480717Z","shell.execute_reply":"2024-04-25T08:43:02.480740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}